{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proj_root(proj_root_marker_file='proj_root.here'):\n",
    "    \n",
    "    max_depth = 10\n",
    "    \n",
    "    def __get_proj_root(folder_path, depth):\n",
    "        if depth == 0:\n",
    "            print('Project root (project_root.here file) is not found!')\n",
    "            return None\n",
    "        \n",
    "        onlyfiles = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "        if proj_root_marker_file in onlyfiles:\n",
    "            return folder_path\n",
    "        else:\n",
    "            parent_dir = os.path.abspath(os.path.join(folder_path, os.pardir))\n",
    "            return __get_proj_root(parent_dir, depth-1)\n",
    "    \n",
    "    return __get_proj_root(os.getcwd(), max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As we are in a Jupyter Notebook - we have to change current working directory \n",
    "os.chdir('../../')\n",
    "os.getcwd()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: darts [-h] [--layers LAYERS] [--batch-size BATCH_SIZE]\n",
      "             [--log-frequency LOG_FREQUENCY] [--epochs EPOCHS]\n",
      "             [--channels CHANNELS] [--unrolled] [--visualization]\n",
      "darts: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-dd4d3f2e-5757-4357-8836-7b3386a5d07c.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py:3334: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "import time\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "sys.path.append('/mnt')\n",
    "sys.path.append('/mnt/skin_cancer_nas')\n",
    "sys.path.append('/mnt/skin_cancer_nas/data/torch_generator')\n",
    "from skin_cancer_nas.data.torch_generator import generator as data_gen  \n",
    "from skin_cancer_nas.data.torch_generator import base_classes\n",
    "from skin_cancer_nas.data.torch_generator import config\n",
    "from skin_cancer_nas.data.torch_generator import preprocessor\n",
    "\n",
    "# import datasets\n",
    "import nas.darts_torch.datasets\n",
    "# from model_melanoma import Combine, CNN\n",
    "from nas.darts_torch.model_melanoma import Combine, CNN\n",
    "from nni.nas.pytorch.callbacks import ArchitectureCheckpoint, LRSchedulerCallback\n",
    "from nni.nas.pytorch.darts import DartsTrainer\n",
    "# from utils import accuracy\n",
    "from nas.darts_torch.utils import accuracy\n",
    "# from base_classes import Dataset\n",
    "# from nas.darts_torch.base_classes import Dataset\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "logger = logging.getLogger('nni')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = ArgumentParser(\"darts\")\n",
    "    parser.add_argument(\"--layers\", default=8, type=int)\n",
    "    parser.add_argument(\"--batch-size\", default=4, type=int)\n",
    "    parser.add_argument(\"--log-frequency\", default=10, type=int)\n",
    "    parser.add_argument(\"--epochs\", default=50, type=int)\n",
    "    parser.add_argument(\"--channels\", default=16, type=int)\n",
    "    parser.add_argument(\"--unrolled\", default=False, action=\"store_true\")\n",
    "    parser.add_argument(\"--visualization\", default=False, action=\"store_true\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # dataset_train, dataset_valid = datasets.get_dataset(\"cifar10\")\n",
    "    partition, labels = data_gen.train_val_split(val_size=0.1)\n",
    "\n",
    "    MEAN = [0.2336, 0.6011, 0.3576, 0.4543]\n",
    "    STD = [0.0530, 0.0998, 0.0965, 0.1170]\n",
    "    normalize = [\n",
    "        transforms.Normalize(MEAN, STD)\n",
    "    ]\n",
    "    train_transform = transforms.Compose(normalize)\n",
    "    valid_transform = transforms.Compose(normalize)\n",
    "    # Generators Declaration\n",
    "    training_set = Dataset(partition['train'], labels, transform=train_transform)\n",
    "    training_generator = torch.utils.data.DataLoader(training_set, **data_gen.PARAMS)\n",
    "    validation_set = Dataset(partition['validation'], labels, transform=valid_transform)\n",
    "    validation_generator = torch.utils.data.DataLoader(validation_set, **data_gen.PARAMS)\n",
    "                    \n",
    "    cnn_model = CNN(input_size=256, \n",
    "                    in_channels=4, \n",
    "                    channels=args.channels, \n",
    "                    n_classes=len(set(labels.values())), \n",
    "                    n_layers=args.layers)\n",
    "    # combined_model = Combine(cnn_model)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optim = torch.optim.SGD(cnn_model.parameters(recurse=True), 0.025, momentum=0.9, weight_decay=3.0E-4)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, args.epochs, eta_min=0.001)\n",
    "\n",
    "    trainer = DartsTrainer(cnn_model,\n",
    "                           loss=criterion,\n",
    "                           metrics=lambda output, target: accuracy(output, target, topk=(1,)),\n",
    "                           optimizer=optim,\n",
    "                           num_epochs=args.epochs,\n",
    "                           dataset_train=training_set,\n",
    "                           dataset_valid=validation_set,\n",
    "                           batch_size=args.batch_size,\n",
    "                           log_frequency=args.log_frequency,\n",
    "                           unrolled=args.unrolled,\n",
    "                           workers=0,\n",
    "                           callbacks=[LRSchedulerCallback(lr_scheduler), ArchitectureCheckpoint(\"./checkpoints\")])\n",
    "    \n",
    "    if args.visualization:\n",
    "        trainer.enable_visualization()\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                       Version\r\n",
      "----------------------------- -----------\r\n",
      "absl-py                       0.9.0\r\n",
      "alabaster                     0.7.12\r\n",
      "astor                         0.8.1\r\n",
      "astunparse                    1.6.3\r\n",
      "attrs                         19.3.0\r\n",
      "autokeras                     1.0.3\r\n",
      "awscli                        1.18.86\r\n",
      "Babel                         2.8.0\r\n",
      "backcall                      0.2.0\r\n",
      "bleach                        3.1.5\r\n",
      "botocore                      1.17.9\r\n",
      "cachetools                    4.1.0\r\n",
      "catboost                      0.23.2\r\n",
      "certifi                       2020.6.20\r\n",
      "cffi                          1.14.0\r\n",
      "chardet                       3.0.4\r\n",
      "click                         7.1.2\r\n",
      "cmake                         3.17.3\r\n",
      "colorama                      0.4.3\r\n",
      "contextlib2                   0.6.0.post1\r\n",
      "coverage                      5.1\r\n",
      "cycler                        0.10.0\r\n",
      "decorator                     4.4.2\r\n",
      "defusedxml                    0.6.0\r\n",
      "docopt                        0.6.2\r\n",
      "docutils                      0.15.2\r\n",
      "ediblepickle                  1.1.3\r\n",
      "entrypoints                   0.3\r\n",
      "flake8                        3.8.3\r\n",
      "future                        0.18.2\r\n",
      "gast                          0.3.3\r\n",
      "gitdb                         4.0.5\r\n",
      "GitPython                     3.1.3\r\n",
      "google-auth                   1.18.0\r\n",
      "google-auth-oauthlib          0.4.1\r\n",
      "google-pasta                  0.2.0\r\n",
      "graphviz                      0.8.4\r\n",
      "grpcio                        1.29.0\r\n",
      "h5py                          2.10.0\r\n",
      "hyperopt                      0.1.2\r\n",
      "idna                          2.9\r\n",
      "imagesize                     1.2.0\r\n",
      "importlib-metadata            1.6.0\r\n",
      "imutils                       0.5.3\r\n",
      "ipykernel                     5.3.0\r\n",
      "ipyparallel                   6.3.0\r\n",
      "ipython                       7.9.0\r\n",
      "ipython-genutils              0.2.0\r\n",
      "ipywidgets                    7.5.1\r\n",
      "jedi                          0.17.1\r\n",
      "Jinja2                        2.11.2\r\n",
      "jmespath                      0.10.0\r\n",
      "json-tricks                   3.15.2\r\n",
      "jsonpickle                    1.4.1\r\n",
      "jsonschema                    3.2.0\r\n",
      "jupyter                       1.0.0\r\n",
      "jupyter-client                6.1.3\r\n",
      "jupyter-console               6.1.0\r\n",
      "jupyter-core                  4.6.3\r\n",
      "Keras                         2.1.6\r\n",
      "Keras-Preprocessing           1.1.2\r\n",
      "kiwisolver                    1.1.0\r\n",
      "lightgbm                      2.2.2\r\n",
      "Markdown                      3.2.2\r\n",
      "MarkupSafe                    1.1.1\r\n",
      "matplotlib                    3.0.3\r\n",
      "mccabe                        0.6.1\r\n",
      "mistune                       0.8.4\r\n",
      "MulticoreTSNE                 0.1\r\n",
      "munch                         2.5.0\r\n",
      "nbconvert                     5.6.1\r\n",
      "nbformat                      5.0.7\r\n",
      "networkx                      2.4\r\n",
      "nni                           1.6\r\n",
      "notebook                      6.0.3\r\n",
      "numpy                         1.18.5\r\n",
      "oauthlib                      3.1.0\r\n",
      "opencv-python                 4.2.0.34\r\n",
      "opt-einsum                    3.2.1\r\n",
      "packaging                     20.4\r\n",
      "pandas                        0.23.4\r\n",
      "pandocfilters                 1.4.2\r\n",
      "parso                         0.7.0\r\n",
      "pexpect                       4.8.0\r\n",
      "pickleshare                   0.7.5\r\n",
      "Pillow                        7.1.2\r\n",
      "pip                           20.1.1\r\n",
      "plotly                        4.8.1\r\n",
      "prometheus-client             0.8.0\r\n",
      "prompt-toolkit                2.0.10\r\n",
      "protobuf                      3.12.1\r\n",
      "psutil                        5.7.0\r\n",
      "ptyprocess                    0.6.0\r\n",
      "py-cpuinfo                    6.0.0\r\n",
      "pyasn1                        0.4.8\r\n",
      "pyasn1-modules                0.2.8\r\n",
      "pycodestyle                   2.6.0\r\n",
      "pycparser                     2.20\r\n",
      "pyflakes                      2.2.0\r\n",
      "Pygments                      2.6.1\r\n",
      "pymongo                       3.10.1\r\n",
      "pyparsing                     2.4.7\r\n",
      "PyQt5                         5.15.0\r\n",
      "PyQt5-sip                     12.8.0\r\n",
      "pyrsistent                    0.16.0\r\n",
      "python-dateutil               2.8.1\r\n",
      "python-dotenv                 0.13.0\r\n",
      "PythonWebHDFS                 0.2.3\r\n",
      "pytz                          2020.1\r\n",
      "PyYAML                        5.3.1\r\n",
      "pyzmq                         19.0.1\r\n",
      "qtconsole                     4.7.5\r\n",
      "QtPy                          1.9.0\r\n",
      "requests                      2.24.0\r\n",
      "requests-oauthlib             1.3.0\r\n",
      "retrying                      1.3.3\r\n",
      "rsa                           3.4.2\r\n",
      "ruamel.yaml                   0.16.10\r\n",
      "ruamel.yaml.clib              0.2.0\r\n",
      "s3transfer                    0.3.3\r\n",
      "sacred                        0.8.1\r\n",
      "schema                        0.7.2\r\n",
      "scikit-learn                  0.20.0\r\n",
      "scipy                         1.4.1\r\n",
      "seaborn                       0.9.1\r\n",
      "Send2Trash                    1.5.0\r\n",
      "setuptools                    47.3.1\r\n",
      "simplejson                    3.17.0\r\n",
      "six                           1.15.0\r\n",
      "smmap                         3.0.4\r\n",
      "snowballstemmer               2.0.0\r\n",
      "Sphinx                        3.1.1\r\n",
      "sphinxcontrib-applehelp       1.0.2\r\n",
      "sphinxcontrib-devhelp         1.0.2\r\n",
      "sphinxcontrib-htmlhelp        1.0.3\r\n",
      "sphinxcontrib-jsmath          1.0.1\r\n",
      "sphinxcontrib-qthelp          1.0.3\r\n",
      "sphinxcontrib-serializinghtml 1.1.4\r\n",
      "ssh-import-id                 5.5\r\n",
      "tensorboard                   1.13.0\r\n",
      "tensorboard-plugin-wit        1.6.0.post3\r\n",
      "tensorboardX                  1.6\r\n",
      "tensorflow                    2.2.0\r\n",
      "tensorflow-estimator          2.2.0\r\n",
      "tensorflow-gpu                1.10.0\r\n",
      "termcolor                     1.1.0\r\n",
      "terminado                     0.8.3\r\n",
      "testpath                      0.4.4\r\n",
      "torch                         1.5.1\r\n",
      "torchvision                   0.2.1\r\n",
      "tornado                       6.0.4\r\n",
      "tqdm                          4.46.0\r\n",
      "traitlets                     4.3.3\r\n",
      "urllib3                       1.25.9\r\n",
      "wcwidth                       0.2.5\r\n",
      "webencodings                  0.5.1\r\n",
      "Werkzeug                      1.0.1\r\n",
      "wheel                         0.29.0\r\n",
      "widgetsnbextension            3.5.1\r\n",
      "wrapt                         1.12.1\r\n",
      "xlrd                          1.2.0\r\n",
      "zipp                          1.2.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-gpu\n",
      "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out. (read timeout=15)\",)': /packages/7a/0b/5b02bc3ef608a6dc06a6ad334977e1be2c275c3cd808db492dccde06145e/tensorflow_gpu-2.2.0-cp35-cp35m-manylinux2010_x86_64.whl\u001b[0m\n",
      "  Downloading tensorflow_gpu-2.2.0-cp35-cp35m-manylinux2010_x86_64.whl (516.2 MB)\n",
      "\u001b[K     |################################| 516.2 MB 58 kB/s s eta 0:00:01     |#################               | 279.0 MB 13.2 MB/s eta 0:00:18     |#####################           | 346.5 MB 29.3 MB/s eta 0:00:06\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.5/dist-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.5/dist-packages (from tensorflow-gpu) (1.12.1)\n",
      "Requirement already satisfied, skipping upgrade: gast==0.3.3 in /usr/local/lib/python3.5/dist-packages (from tensorflow-gpu) (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.5/dist-packages (from tensorflow-gpu) (3.2.1)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/lib/python3/dist-packages (from tensorflow-gpu) (0.29.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.5/dist-packages (from tensorflow-gpu) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.5/dist-packages (from tensorflow-gpu) (2.10.0)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.5/dist-packages (from tensorflow-gpu) (0.9.0)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.5/dist-packages (from tensorflow-gpu) (1.1.2)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /usr/local/lib/python3.5/dist-packages (from tensorflow-gpu) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /usr/local/lib/python3.5/dist-packages (from tensorflow-gpu) (3.12.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.5/dist-packages (from tensorflow-gpu) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: astunparse==1.6.3 in /usr/local/lib/python3.5/dist-packages (from tensorflow-gpu) (1.6.3)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.5/dist-packages (from tensorflow-gpu) (2.2.0)\n",
      "Collecting tensorboard<2.3.0,>=2.2.0\n",
      "  Using cached tensorboard-2.2.2-py3-none-any.whl (3.0 MB)\n",
      "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.8 in /usr/local/lib/python3.5/dist-packages (from tensorflow-gpu) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.5/dist-packages (from tensorflow-gpu) (1.29.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.5/dist-packages (from protobuf>=3.8.0->tensorflow-gpu) (47.3.1)\n",
      "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.5/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (2.24.0)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.5/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (0.4.1)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.5/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (1.18.0)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.5/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (3.2.2)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.5/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.5/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (1.6.0.post3)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.5/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (1.25.9)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.5/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.5/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.5/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (2.9)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.5/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.5/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (3.4.2)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.5/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (0.2.8)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.5/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (4.1.0)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.5/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (1.6.0)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.5/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.5/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (0.4.8)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.5/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (1.2.0)\n",
      "Installing collected packages: tensorboard, tensorflow-gpu\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 1.13.0\n",
      "    Uninstalling tensorboard-1.13.0:\n",
      "      Successfully uninstalled tensorboard-1.13.0\n",
      "  Attempting uninstall: tensorflow-gpu\n",
      "    Found existing installation: tensorflow-gpu 1.10.0\n",
      "    Uninstalling tensorflow-gpu-1.10.0:\n",
      "      Successfully uninstalled tensorflow-gpu-1.10.0\n",
      "Successfully installed tensorboard-2.2.2 tensorflow-gpu-2.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-gpu --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.5/dist-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.14 in /usr/local/lib/python3.5/dist-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.5/dist-packages (from keras) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.5/dist-packages (from keras) (5.3.1)\n",
      "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.5/dist-packages (from h5py->keras) (1.15.0)\n",
      "Installing collected packages: keras\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: Keras 2.1.6\n",
      "    Uninstalling Keras-2.1.6:\n",
      "      Successfully uninstalled Keras-2.1.6\n",
      "Successfully installed keras-2.4.3\n"
     ]
    }
   ],
   "source": [
    "!pip install keras --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dockerfile\t\t    SimpleCNN_triple-subreg_v6\tnotebooks\r\n",
      "LICENSE\t\t\t    checkpoints\t\t\tproject_root.here\r\n",
      "Makefile\t\t    data\t\t\treferences\r\n",
      "README.md\t\t    docker-compose.yml\t\treports\r\n",
      "SimpleCNN_triple-subreg_v1  docker_clean_all.sh\t\trequirements copy.txt\r\n",
      "SimpleCNN_triple-subreg_v2  docs\t\t\trequirements.txt\r\n",
      "SimpleCNN_triple-subreg_v3  image_classifier\t\tskin_cancer_nas\r\n",
      "SimpleCNN_triple-subreg_v4  logs\t\t\tstart.sh\r\n",
      "SimpleCNN_triple-subreg_v5  models\t\t\ttox.ini\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
